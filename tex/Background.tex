\chapter{Background And Literature Review}\label{chapter:Background}
\section{Background}
The notion of asymmetric loss is not something that is new. The method can be traced back to the 1980's when Roger Koenker published a paper on the idea of estimating quantiles using quantile regression \citet{Koenker78}. \citep{Koenker78} realized instead of a mean estimate, it may be useful to obtain a quantile estimate in certain situations. For instance the 90th percentile of heights of males. For such problems optimizing the squared error loss, even though it is computationally convenient, leads to bias estimates \citep{Koenker01}. Getting an estimate of the quantiles for least squares regression is feasible. In a regression model, we know that $f(Y|X)\sim N(E[Y|X],\sigma^2)$. Thus from the normal distribution, one can determine a quantile estimate based on the following equation
\begin{equation}
	\hat{\tau_\theta} = \Phi^{-1}(\theta) \sigma + E[Y|X]
\end{equation}
where $\theta$ is the quantile,  $\Phi^{-1}(\cdot)$ is the inverse standard normal distribution, and $\sigma$ is the model's standard deviation. This parameter approach, although simple to implement, is subjected to the assumptions of least squares which specifies that the residuals are normally and identically distributed. A departure from such assumptions will certainly result in a bias quantile estimate  even though it will not affect the least squares estimate of the mean. The departure of the normality of the errors have been tackled in the literature via using Box-Cox transformations \citep{Wei06}. However, implementing such a transformation in practice may be problematic if it violates the domain understanding of the problem. Thus just using the $z$-estimate of a quantile is not a robust way of estimating the percentiles. To discover quantile estimates, there be to be a more robust model estimation that is able to be robust under uncertain conditions.

\section{Quantile Regression}
Quantile regression has been used successfully in many applications. In \citet{Bassett07}, quantile regression was used to measure the handicap of football games. A decision to use quantile regression was appropriate in trying to understand the probability of the score difference in a game which would then be used as a measure for a future game's handicap. \citet{Hewson08} uses quantile regression to assess local government based on a set of performance indictors. They try to match relative performance based on the upper and lower quartile. Good estimates required that quantile regression be used and modified to model the binary responses. The paper also showed the viability of quantile regression in a Bayesian framework by trying to solve for a credible interval for the coefficients of covariates. These covariates provide insights into the reasons why local governments out-perform or under-perform their peers. \citet{Wei06} uses quantile regression for estimating the growth charts of children's heights and weights. As presented in the work, traditional regression modeling lacks the robustness that quantile regression offers. \citet{Christmann08} took regular quantile regression and added a kernel.  The paper showed that the non-linear transformation transformation of a radial basis function kernel is valid and consistent for the loss function. Using the radial basis function kernel and simulated results, the paper showed how quantiles can be obtained from non-linear data. 

\section{Exploring the loss functions}
\begin{figure}
 \centering
\includegraphics[width=3.4in]{img/imagesBackground/background_lossfunction}\\
 \caption{Loss function for absolute error and quadratic loss. The diamonds show the loss for absolute error and the squares show the quadratic loss. The cost of loss increases quadratically for the quadratic loss, from being equal with the absolute error when the loss is 1, to being 5 times the magnitude when the loss is 5.}
 \label{Fig:L1L2Loss}
\end{figure}

The difference between least squares regression and quantile regression lies in the loss function of these two methods. The loss function quantifies the difference between the predicted and the actual result and is expressed as $L(Y,f(X))$ \citep{Hastie01}. For a regular least squares regression, the loss function is as follows
\begin{equation} \label{L2loss}
	L(Y,f(X))=(Y-f(X))^2
\end{equation}
Minimizing the loss function reduces the risk of errors. If predictions are 100\% accurate, the value of the loss function is 0. The magnitude of a loss function is always non-negative. When used in machine learning algorithms, the loss function is made the objective function which is being minimized. Observing equation \ref{L2loss}, we see that the difference between Y-f(X) gets penalized in a squared fashion which follows that the marginal degree of penalization is proportionally larger. As the margin of penalization increases with the magnitude of difference, it is more likely that a model is susceptible to being heavily trained by the outliers of the dataset. An alternative is to penalize marginal magnitude equally as shown in the below equation
\begin{equation}\label{L1loss}
	L(Y,f(X))=|Y-f(X)|
\end{equation}
Here the results has a constant marginal penalization rate and the resulting model will be less dictated higher magnitude errors. We see that by changing the loss function, we can obtain models that exhibit different characteristics. \citet{Steinwart07} has formalized the ways of comparing loss functions by using surrogate functions and identifying which functions are better in terms of computational requirements and robustness concerns. In the construction of many algorithms, the objective loss function may be either too computationally intensive or may not be robust. Using another loss function, which is called a surrogate, that is similar to the original loss function can be made so that the new minimization loss function problem will be less computationally intensive or the learning can be more robust. The paper gives criteria for suitable surrogate loss functions. The criteria allows for creativity with loss function designs to allow the learner to accomplish different objectives. For instance, the condition that the errors of difference signs has to be the same can be relaxed and the resulting model would be more accurate in predictions on one side of the error than the other. This kind of design is known as asymmetric loss. 

Asymmetric loss has been widely explored in the literature. In the psychology literature, \citet{Weber94} showed that asymmetric cost is present in people's decision making. The paper tries to quantify asymmetry cost psychologically. It discusses how people rank outcomes in a relative way instead of an absolute way, paying too much attention to a decision has higher cost and paying too little attention to that which has little cost. Finally it uses stochastic dominance to justify the asymmetry in decision where even though the expectations are the same, a stochastically dominant choice is preferred. \citet{Huang01} proposed a new model that takes both quality and cost into account. The model is an extension of the classical Taguchi \citep{Taguchi95} quality model where only quality is controlled and it tries to find a balance between quality and cost. \citet{McCullough00} created a generalized loss function that can account for asymmetry to use for modeling of interest rates. \citet{Koenker01}, in rationalizing quantile regression, understood that to build a model for estimating quantiles, the loss function would have to be asymmetric, penalizing residuals with different signs differently. \citet{Pattona06} showed evidence that mean loss is not optimal for problems that are innately asymmetric, particularly in a non-linear model. When an artificial data set that is constructed to be unbalanced such that the proportion of class instances are either much less or much more than 50\%, the use of mean loss often leads to bias results. The paper showed that modeling of stock prices are optimal only under certain strict restrictions and thus conventional modeling techniques such as squared error loss are not robust to changing conditions. Changing conditions will exist when a predictor relationship with the response is non-symmetric. This paper highlights conditional variance (see \citet{Hentschel95} for an explanation of conditional variance in time series modeling) as an example where the predictors relationship is non symmetric and the mean loss function fails to provide good estimations of the time-series being modeled. \citet{Pattona06} presented a more generalized framework to accommodate asymmetric loss in stock price modeling which includes the use of transformation of the errors and using asymmetric loss functions such as linear-exponential loss. The paper stressed that given the non-symmetric nature of stock price movement, it is critical to create models that are more robust to deviations from the current stock forecast models. \citet{Demetrescu07} presented an optimal criterion for forecast intervals under asymmetric loss functions. In forecasting times-series data, one has to be concern with the bounds of error. However, if one is concern about the direction of violation of the forecast, an optimal forecast interval should account for the risk associated with violations on different sides of the interval. The paper showed how to construct optimal bounds with different risk expectations using asymmetric loss. 

\section{Uneven datasets}
In addition to minimizing risk in different directions, asymmetric loss can also be useful in classification problems where the training dataset where the proportion of response classes are significantly different. This is known as the unbalanced dataset problem. The example of such problems spans many fields, from the detection of oil spills \citep{Kubat98}, to detecting fraud in mobile communications \citep{Fawcett97} and credits cards, to predicting when a manufacturing process will fail \citep{Riddle94}, to diagnosing rare diseases \citep{Laurikkala01}. This section provides an overview of how the class imbalance problem has been handled in the academic literature. \citet{Daskalaki06} explored the various ways that such uneven datasets can be handled and showed that asymmetric learning is able to improve the results of detecting the class that has fewer samples. The paper showed that various learners such as neural network, C4.5, and logistic regression all fail to adequately classify the class that has the least proportion in the training dataset. However, by using a voting algorithm described in the paper, the ability of correctly classifying the minority class can be improved. Asymmetric prediction of unbalanced data can be managed by applying asymmetric SVMs \citep{Changha05} \citep{Huang05}. \citet{Cohen03} uses an asymmetric SVM to tackle the imbalance problem in the Surveillance of Nosocomial Infections. The problem the paper is faced with is the percentage of positive cases in the dataset is about 11\% which results in the learner, which in this case is SVM, always predicting the negative class in the out-sample. Adjusting the loss function of the SVM such that there is asymmetry causes the SVM to be more sensitive to positive cases. The result of making such a modification causes the learner to be able to pick the positive class. \citet{Wu03} showed how asymmetric loss is used in $\nu$-SVM so that one can classify unbalanced datasets. For a better understanding of $\nu$-SVM, please refer to \citet{Scholkopf00}. The paper proposed 2 modifications to $\nu$-SVM. The first is controlling the ratio of misclassification cost directly within the construct of the $\nu$-SVM equation. As the value of $\nu$ controls the trade off between a larger margin and smaller trading error, the second proposed modification uses two $\nu$ values in the construct of the $\nu$-SVM, one for the positive class and the other for the negative. The paper then applied its methods to text categorization where the dataset is highly unbalanced. The results concluded that asymmetric modifications performs better than the regular $\nu$-SVM when classifying an unbalanced dataset. 

\section{Linear Exponential Loss (LINEX)}
\begin{figure}
 \centering
\includegraphics[width=3.4in]{img/imagesBackground/LINEX}\\
 \caption{Loss function for LINEX. When the error is negative, the loss function is linear. When the error is positive, the loss is exponential. Thus the training is controlled by the outlier observations on the positive side and controlled equally by all observations on the negative side.}
 \label{Fig:backgroundLINEXLoss}
\end{figure}
The loss function used in quantile regression, known as the pinball \citep{Takeuchi06}, is a common asymmetric loss function that is used. However, it is not necessarily the only loss function that provides asymmetric loss. The LINEX loss function is another proposed loss function with a desired property of being sensitive to outliers on one side and not on the other \citep{Chang07}. \citet{Christoffersen97} shows the use of LINEX loss in time series estimation where the errors may not necessarily be normally distributed. LINEX loss can be expressed as below.
\begin{equation}
	L(Y,F(X))= e^{\alpha(Y-f(X))}-\alpha(Y-f(X))-1
\end{equation}
where $\alpha$ determines the side that is linear and the side that is exponential where if $\alpha>0$, the loss is approximately linear to the left of the origin and exponential to the right. The converse is true when $\alpha <0$. Statistical parameters have been estimated with the aid of LINEX when the underlying distribution is non-symmetric. \citet{Giles93} uses the LINEX model to predict the scale parameter for regression where we would like to be more conservative in its quantity. Conventional estimation in regression uses the squared-error loss and as the resulting estimated parameters are used for coefficient estimates and t-statistics, an under-estimation of a parameter such as the variance may lead to misleading results of coefficient significance. This prompts the need to use a loss function that is less restrictive and can be manipulated to be robust in parameter estimation. They show that the estimated results from LINEX are robust when the underlying errors in the data are mildly different from a normal distribution. However, in more extreme departures from a normal distribution, the paper concludes the resulting outcomes are less robust. The use of LINEX has been successfully applied to ridge regression. In \citet{Ohtani95} and \citet{Fikri03}.

\section{Bayesian Asymmetric Loss}
The work of asymmetric loss has been studied for use in Bayesian statistics, both in the likelihood function and in estimating credible intervals. \citet{Hans06} used asymmetric loss to construct credible intervals in the estimation of the binomial parameter. The need for asymmetric loss for this estimation arose from the monitoring of public health systems where cost of overestimation and underestimation has different cost. The sample size is optimized based on an asymmetric approach applied to the likelihood function. Under certain unspecified prior distributions, \citet{Kaminska09} proved that Bayesian estimators can be constructed with a bounded asymmetric Bayesian loss. The paper proposed a loss function called Bounded and asymmetric loss (ABL) which is in the following form

\begin{equation}
	L(\upsilon, d)= K(1-(\frac{\upsilon}{d}e^{1-(\theta/d)})^\gamma)
\end{equation}
where $K >0, \gamma > 0$ are known parameters. $K$ represents the maximum loss and $\gamma$ determines the shape. The loss function presents a robustness that winsorizes the extreme outliers. This kind of winsorization has also been applied to LINEX in a method known as Bounded asymmetric loss BLINEX. \citet{Wen01} presented the BLINEX loss function as follows 
\begin{equation}
	\frac{1}{\lambda} \left [ 1-\frac{1}{1+\lambda c(e^{ax}-ax-1)} \right ]
\end{equation}
Like ABL, BLINEX is also a robust estimator in that extreme outliers get winsorized. The paper showed that with BLINEX, the Bayes estimate of a parameter is unique and exists.

\section{Asymmetric Bagging}
We have thus far seen that asymmetric loss is useful in various different applications, both in the theoretical literature as well as the applied realm. The question now is if work has been done in the area of ensembles where asymmetric loss is applied on the ensemble method to the learners instead of within the learners. \citet{Tao06} uses bootstrapping with SVM learners to manage the problem of small datasets, and unbalanced dataset. Bootstrapping is simply sampling the original dataset with replacement to recreate a bootstrapped dataset that is used for training. One can conduct bootstrapping such that the bootstrap dataset has certain characteristics that are different than the original dataset. An example of this is sampling from an unbalanced dataset such that the bootstrap dataset is balanced. Bootstrapping provides an exogenous learning environment where the training data, because it is being manipulated, is also actively involved in the training process. To take on the problems presented in \citet{Tao06} paper, bagging was conducted in 3 ways: bootstrapping the cardinality of the dependent variables to be trained in the classifiers, bootstrapping the dependent variable, and doing both of the aforementioned ways simultaneously. The first way takes care of having more predictors than observations, the second way takes care of the unbalanced dataset problem, and the third combines the benefits of the previous 2 ways. The paper showed that SVM has an over-fitting problem and is biased in an uneven training dataset. Thus the bootstrapping methods mitigated these issues and produced compelling results. 

 \citet{Li08} evaluates the efficacy of asymmetric methods applied within an algorithm such as SVM and also outside of an algorithm such as the use of bagging. The paper applied these methods to an unbalanced dataset of drug molecules activities. The results showed that, in the case of an asymmetric method applied within an algorithm, an asymmetric SVM does not provide any incremental value over a regular SVM. Asymmetric bagging on the other hand, provides considerable improvements to just regular bagging of SVM learners. The paper also included their own modification to asymmetric bagging. Known as PRIFEAB bagging, the learner removes irrelevant and redundant features before performing the bagging algorithm to modestly improve the performance of asymmetric bagging. 

Bagging in the form of trees are known as random forests. Asymmetric random forest has also been studied in the literature. One of the papers that explore asymmetric random forest is \citet{Meinshausen06} where it the idea of using quantile regression to get prediction intervals for ozone levels and outlier detection was proposed. The key difference between quantile regression forests and random forests is as follows: for each node in each tree, random forests computes the mean of the observations that fall into this node and neglects all other information. In contrast, quantile regression forests keeps the value of all observations in this node, not just their mean, as this is needed to find the conditional quantile given an observation. Quantile regression forests (QRF) is applied to various popular data sets from the machine learning literature and results are compared to various other quantile regression methods: linear quantile regression with interactions (QQR) and without interactions (LQR), and quantile regression trees with piecewise constraints (TRC), piecewise multiple linear (TRM), and piecewise second-degree polynomial form (TRP). The results showed QRF to be robust in various simulated datasets.

\section{Asymmetric Boosting}
Apart from bagging, boosting is also another form of ensemble where asymmetric learning can be applied \citep{Hamed04}. \citet{Mease07} discusses quantile estimation and class probabilities in Logitboost and Adaboost. These algorithms were used to estimate probabilities of being in a particular class and these probabilities are used as thresholds to establish quantiles. Jittering over and under sampling (JOUS) with Adaboost was also used. Algorithms like Adaboost trains a learner serially. Each successive learner trained is fed with training data that had been transforms by a cost factor. To get asymmetric classification is easy as one has to change the cost constant to something other than the median. The authors comment that the boosting of asymmetric classifiers must stop early as they are prone to overfitting. This is because the longer the boosting process, the more likely the classification probability either limits to 1 or 0. The method suggest that JOUS performs better than adjusting the cost. 

\citet{Viola06} talks about cases where fast detection is more relevant than accurate detection. In using asymmetric Adaboost to detect faces, the paper shows that asymmetric Adaboosting AUC is better than regular Adaboost. Also the asymmetric Adaboost can be used as a speedy filter to filter through the false negative such that the dataset is vastly reduced and another more accurate trainer can be used to identify the faces. \citet{Fenske09} uses gradient boosting of regular regression to estimate the bottom 5\% of children nutritional scale to identify children at risk of malnutrition. Additive quantile regression is applied \citep{Lee05} with a proposed asymmetric boosting algorithm that is as follows
\begin{enumerate}
	\item Regress the initial dataset and get estimates $\hat{\eta}$
	\item use the following negative gradients to compute the empirical risk $u_i$
	\begin{equation}
		u_i=\rho'_\tau (y_i -\hat{\eta}_i^{[m-1]})=\begin{cases} \tau & y_i-\hat{\eta}_i^{[m-1]} >0
		\\
		0 &y_i-\hat{\eta}_i^{[m-1]} =0
		\\
		\tau - 1 & y_i-\hat{\eta}_i^{[m-1]} <0
		\end{cases}	
	\end{equation}
	\item Regress $u_i$ on the original paramters
	\item repeat from 2 until the desired number of iterations. 
\end{enumerate}

$\eta$ is the predicted values from the trained model based on the minimization of least squares. Using this boosting algorithm allows for there to be non-linearity as oppose to just using a single least squares regression model. \citet{Chaudhuri02} uses the GUIDE algorithm \citep{Chaudhuri95} to form quantile regression trees. The quantile estimation is done on the trees themselves instead of in the boosting process. Trees are split using the residuals available after splitting the tree and piecewise polynomials are used for each node of the tree. The size of piecewise polynomial regression tree models can be adjusted by changing the form of the polynomial fitted at the nodes which allows the tree to not be as large as a constant regression tree model. 

\section{Asymmetric variables}
%Need at least 5 papers
If there is a way to choose predictors that are apt in predicting the response, we would be able to construct a better model. Specifically for asymmetry, we do not need the variable to be apt at predicting all values of the response, only the specific value that we want to focus on. Let $y \in (-1,1)$, we have a model $f(\mathbf{x})=y$ where $\mathbf{x} = (x_1,x_2,...,x_p)$ and $x_{i} \in P$. We would like to find a set of $x$'s such that $\displaystyle\max_{\mathbf{x}}P(y=1,f(\mathbf{x})=1)$. Finding variables that maximizes the function $\displaystyle\max_{\mathbf{x}}P(y=f(\mathbf{x}))$ has been widely studied in the literature and is the basis for most variable selection algorithm. 

There are three main ways the variable selection is conducted \citep{Saeys07} : filter, wrapper, embedded. The filter selection techniques assesses the intrinsic properties of the predictor and assigns a score. The variables with the best scores are the picked. The simplest filters come in the form of t-stat or ANOVA  \citep{Jafari06}. Correlation based feature selection (CFS) is a method that picks variables with high correlation to the dependent variable and low correlation to the other independent variables \citep{Hall99}. Similar to CFS is the minimum Redundancy Maximum Relevance Feature Selection (mRMR) which is based on the concept of gathering a subset of independent variables that are highly predictive of the dependent variable and highly dissimilar with other independent variables \citep{Ding03}. Markov blanket filter builds a Markov blanket that contains a minimal subset of relevant features that yields optimal classification \citep{Zeng09}. 

Wrappers utilize a learning algorithm as a black box to score subsets of variable according to their predictive power. The wrapper methodology was popularized by \citet{Kohavi96} and is a simple and powerful way to address the problem of variable selection, regardless of the chosen algorithm. Some popular known wrapper algorithms include sequential forward and backward selection \citep{Kittler78}, zimulated annealing\citep{Kirkpatrick83}, randomized hill climbing \citep{Skalak94}, genetic algorithms \citep{Holland75}, and estimation of distribution algorithms (EDA) \citep{Blanco04}. Sequential forward and backward selection uses regression as the learner to decide the best subset of variables that are relevant. Simulated annealing, randomized hill climbing and genetic algorithms both use some form of randomness to find a subset of variables that are pertinent for model prediction. The estimation of distribution algorithm is a general version of the genetic algorithm. When iterating a genetic algorithm to find the best subsets, equal priors are placed on each of the variables in the current subset. In EDA, the priors are updated and represents a probability distribution of the variable's pertinence. 

For embedded methods, the search for a best subset of features is built into the classifier construction, and can be seen as a search in the combined space of feature subsets and hypotheses. This process may be more efficient in several respects. First, it makes use of the available data by not needing to split the training data into a training and validation set. Second, it reaches a solution faster by avoiding retraining a predictor from scratch for every variable subset investigated. Embedded methods are not new: decision trees such as CART \citep{Breiman84}, for instance, have a built-in mechanism to perform variable selection. Random forest is an algorithm that is widely used in the literature as an embedded system for variable selection \citep{Diaz06}\citep{Jiang04}. A variant of SVM known as SVM with recursive feature selection is an SVM method that has an embedded feature selection technique \citep{Guyon02}. Finally \citet{Ma05} tweaks the logistic regression method to produce an embedded method that eliminates variables with small weights.

A review of the methods in the literature failed to shed light on finding variables that are particularly good at asymmetric prediction. Asymmetric variables appear to be an area that has not been widely studied. However, asymmetric variables appear to be prevalent in the literature. \citet{Matzler04} did a regression analysis to find out what attributes lead to better overall customer satisfaction. They showed that for variables of complaint handling, project management, and innovativeness, when the performance is low, there is a significant effect on overall satisfaction. However, when these same variables showed high performance, the effect on overall satisfaction is insignificant. \citet{Froyen97} studied whether political pressures add significant explanatory power in monetary policy. They found that in white house administrations that pressure the Federal Reserve to tighten monetary policy results in higher interest rates whereas in white house administrations that promote loose monetary policy does not affect the interest rates. Finally \citet{Karras97} identified money-supply shocks and their effects on output for a panel of 18 European countries and found that many different specifications and estimation methods strongly support asymmetry: negative money-supply shocks are shown to have a statistically significant effect on output, whereas the effect of positive shocks is statistically insignificant. 









