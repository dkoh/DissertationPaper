\chapter{Asymmetric SVM Paper}\label{chapter:SVMpaper}
\section{Abstract}\label{Abstract}
Support Vector Machines (SVM) uses a hinge loss function to penalize false predictions, regardless of whether the false prediction was that of a positive prediction or a negative prediction. In many healthcare problems, the accuracy of predicting a positive class is more important than the prediction of a negative class. Such asymmetric problems require a robust loss function that would allow different penalization for the nature of false prediction. A generalized asymmetric loss function is presented and applied to two kinds of problems: the optimization of precision, and the training of unbalanced data. Using the blood transfusion data from UCI, the asymmetric SVM was able to improve precision from 76\% to 100\%. To show the ability of training an uneven dataset, an unbalanced blood transfusion dataset was used where the number of true-positives was doubled without any loss of precision.

\section{Introduction}\label{Introduction}

The most common data mining techniques are trained to make predictions by minimizing the error rate. In a naive fashion these techniques possess a loss function that penalizes errors by being impartial to whether the error is that of a false-positive (FP) or a false-negative (FN). Ignoring the sign of the error $y-f(x)$ throws out information about the nature of the error which proves important in some applications. There are a class of problems where the optimization of errors are focused solely on the ability to identify a positive class accurately. For such problems, the ability obtain true-positives (TP) is more important than obtaining a true-negative (TN). It may not be as important to miss some positives as long as there are not a lot of false-positives. For instance, the lawsuit that ensues from wrongly accusing a patient of medical fraud is more punitive than allowing the fraud to happen \citep{Liou08}. Correctly identifying a fraud case can be thought of as a TP while wrongly accusing a party can be thought of as a FP. Thus, ensuring that when a fraud case is identified, it is with high probability that the identification is correct. By defining precision as
 \begin{equation} \label{Eq:precision}
Precision=\frac{TP}{TP+FP}
\end{equation}
, such problems are handled by optimizing the precision instead of the maximizing both TP and TN simultaneously. 

This paper presents a generalized loss function that allows for asymmetric learning to occur. Not only would a generalized loss function result in better precision, it can also be applied to a common phenomena in many datasets where the training data has much more observations for one class. Such imbalances typically result in a trained classifier that is unable to classify the class that has less observations in the training dataset. The imbalance dataset problem has often been mitigated in the literature with the utilization of an asymmetric resampling methodology that produces a training dataset that has a more even distribution of observations between classes \citep{Hamed04}. This paper attempts to tackle the challenges of precision optimization and the imbalance dataset problem by substituting the conventional hinge loss in support vector machines (SVM) with a generalized asymmetric loss function. The application of the asymmetric loss function within the SVM framework is explored where the parameters of the loss function are varied to improve precision and/or increase the number of observations classified positive. Allowing for different weights to be applied to the training algorithm of SVM such that an over prediction would have a different penalizing weight than that of an under prediction of the same magnitude, the generalized asymmetric loss presented is an extension of the pinball loss function \citep{Steinwart07} used in quantile regression. With this asymmetric penalization, the SVM can be trained to be more selective in classifying a positive class to reduce the probability of a false-positive. It can also be used as alternative to the resampling approach of unbalanced datasets by allowing for greater penalization for the majority class when training an SVM. This would be an advantage over the resampling methodology as it maintains the integrity of the original data.

The paper is organized as follows. Section \ref{motivation} presents the motivation of using an asymmetric loss function in the healthcare industry by presenting papers that would have been better off if asymmetric loss functions were introduced. Next, quantile regression is presented to establish the pinball loss function and how it is effective at optimizing losses asymmetrically. Section \ref{generalform} presents a generalized asymmetric loss function and integrates this into the SVM algorithm. Section \ref{simulation} illustrates how the generalized asymmetric loss function can be tuned to obtain different results with a simulated bi-variate normal distribution dataset. The remaining sections show how the generalized asymmetric SVM can be applied in the health care field by varying the parameters of the loss function to either obtain higher precision or higher hit rates of one class.

\section{Background}\label{background}
\subsection{Motivation}\label{motivation}

Much machine learning done in the healthcare field utilizes a symmetric loss function to train the presented classifier. However, many of the objectives in the medical field require the use of asymmetry. For instance, which treatment gives a patient the highest probability of success, or which set of genes are most likely to cause cancer are examples of questions that would require the use of asymmetric loss. Moreover, data obtained from the medical field often have disproportionate classes which makes it hard for many classifiers to learn to differentiate the data. In this section two papers in the healthcare literature are presented. Both papers try to tackle a problem which could be better managed if there was an asymmetric loss function applied to the problem.

\citet{Liou08} published an article on detecting frauds and claims for diabetes. Diabetes has become the leading chronic disease among the elderly due to changes in dietary habits and lifestyle in Taiwan. The disease has ranked fourth among the leading causes of death in Taiwan ever since 1987. The detection of fraud and abuse thus remains an important task in cost savings. However, the false implication of fraud may bring forth lawsuits and consume resources. Thus it would be prudent to identify cases which has a high probability of being fraudulent. A random sample of cases from 17668 healthcare providers was obtained from the National Health Research Institute. The study uses nine expense related variables in various detection models that have previously been found useful in detecting fraudulent cases \citep{Yang06}. Logistic regression, neural network, and classification tree are used to predict fraud. As these classifiers are known to perform better if they are trained on an evenly balanced dataset, the paper uses an algorithm of resampling to yield a transformed dataset with equal observations for each class. The paper was able to predict fraud with much success using the C4.5 algorithm whereas logistic regression and neural network were not as accurate. The paper's objective of maximizing the number fraud prediction while minimizing false positives were not addressed directly by the methods employed. 

A lot of work have been done in the healthcare machine learning field to try and detect the differences in gene expressions between normal tissues and cancerous tissues \citep{Ambroise02}\citep{Guyon02}. Being able to discern between cancer and normal tissues would be useful for genetic diagnosis and drug discovery. The literature suggests that it is possible to construct a prediction rule from a subset of genes in micro-array data and achieve relatively good prediction error rates. Although the prediction error rates are low, the algorithms employed lack the risk aversion feature which would minimize situations where expressions that are not cancerous are wrongly classified as cancerous. \citet{Guyon02} analyzed DNA micro-array data to determine which genes are active in cancer tissues. The paper uses a method of variable selection known as Recursive Feature Selection where a support vector machine is trained and then analyzed to find the features that contributed the least weight to the model. That feature is removed and the process is repeated. The process is similar to that of a backward elimination process of linear regression. Two datasets, a leukemia and a colon cancer dataset, were used to demonstrate the ability of accurately flagging expressions that are cancerous. Even though the results yield proved impressive, the methods employed do not take into account the false positives in the results and thus it would be beneficial to employ an asymmetric method to verify if the precision of prediction would improve.

\citet{Huang05} realized the problem of uneven training class sizes where there is a bias towards predicting the class with greater observations in the training dataset. The paper proposed using a weighted methodology for each training observation to mitigate the problem of the bias. The class with less observations is given more weight per observation. The weighted SVM technique was applied to the breast cancer diagnosis dataset available on the UCI database where only 10\% of the training data was classified as malignant but better results were not obtained over the regular SVM for the classification of malignant cases. \citet{Cohen03} tackled the same problem in the heathcare field but instead of using a weighted approach, the authors used an asymmetric margin where different penalties where assigned to classifying the wrong class. This method uses the pinball loss function to assign the different penalties. The method was applied to the identification of nosocomial infections from Geneva University Hospital. The training data had 10\% of the observations labeled as positive. The pinball loss employed was able to increase the accuracy of prediction by 5\% over the baseline of a regular SVM. The methodology implemented in the paper is similar to what is being proposed. Thus, this paper complements the work done by \citet{Quadrianto09} with the introduction of a more general form of the pinball loss function.

\subsection{Quantile Regression}
To understand how asymmetry works it is necessary to first discuss the pinball loss function found in quantile regression. Even though this loss function is commonly used in a regression context, it will be used to handle the classification problems addressed in this paper. The pinball loss is not the only kind of asymmetric loss function in the literature. Other forms of asymmetric loss include linex \citep{Demetrescu07} \citep{Ohtani95}, and ramp loss \citep{Takeuchi06}. However, the pinball loss resembles the loss function used in a support vector regression machine and thus it is more natural to generalize the loss function instead of force fitting a different loss function. In least square regression, the conditional expectation of the target, $y$, is used as the solution that minimizes the the expression $E[(y-f(\mathbf{x}))^2]$. While the aforementioned expression results in a prediction of the mean, it may not be the optimal estimate of $y$ for some applications where objective is not maximized by finding the expected value. When it is more important to derive a good estimate that satisfies the property that a proportion, $\theta$, of $f(\mathbf{x})$ is less than y, the quantiles of the conditional distribution should be optimized instead of that of the expected value. The value of $\theta$ denotes the quantile of the data. By denoting $y \in \mathbb{R}$ as random variable and $\theta \in (0,1)$, the $\theta$-quantile of y, denoted by $\mu_{\theta}$ is given by
 \begin{equation}
 \inf_{\mu}P(y\leq \mu)=\theta
 \end{equation}
when $\theta = 0.5$ the median is achieved. The conditional quantile $\mu_{\theta}(\mathbf{x})$ for a pair of random variables $(x,y) \in \mathbb{R}$ is defined as the function $\mu_{\theta}(\mathbf{x}) $ where the point $\mu_{\theta}$ is the solution to the following equation.
 \begin{equation}
 \inf_{\mu}P(y\leq \mu|\mathbf{x})=\theta
 \end{equation}
The basic strategy to obtain quantile estimates arises from the observation that minimizing the L1-loss function for a location estimator yields the median. Observe that to minimize the following expression
\begin{equation}
\min_{\mu}\sum_{i=1}^{m}|y_i-\mu|
 \end{equation}
by choice of $\mu$, an equal number of terms $y_i-\mu$ have to lie on either side of zero in order for the derivative with respect to $\mu$ to vanish. \citet{Koenker01} generalizes this idea to obtain a regression estimate for any quantile by tilting the loss function in a suitable fashion. This is known as the pinball loss function. The pinball loss leads to estimates of the $\theta$-quantile by the following:

\begin{equation}\label{Eq:pinball}
l_{\theta}=
\begin{cases} \theta (y-\hat{y}) & \text{if $(y-\hat{y})\geq 0$,}
\\
 (\theta - 1) (y-\hat{y})  &\text{if $(y-\hat{y})< 0$.}
\end{cases}
\end{equation}

Let $m$ be the total number observations. The number of observations with $y_i < \mu_{\theta}$ is bounded from above by $m\theta$ and the number of terms with $y_i > \mu_{\theta}$ is bounded from below by $m(1-\theta)$. This condition ensures that as m approaches infinity, the number of terms below $\mu_{\theta}$ to the total number of terms converges to $\theta$. This becomes a problem that can be solved by optimization where the objective is to minimize the error loss from (\ref{Eq:pinball}). Linear optimization programs such as CPLEX can be used to solve the minimization problem. Figure \ref{Fig:Quantile Regression} gives a graphical example of quantile regression for different values of $\theta$. Quantile regression using support vector regression has been well studied in the literature \citep{Changha05} and has been successfully applied to linear and non-linear data. However little focus is given to the modification of the loss function or even the generalization of such functions. For the applications mentioned in section \ref{motivation}, it is more important to focus the training on the subset of training data that matters most. Practical examples of such subset optimization include finding the subset of $x$ that yields that highest proportion of positive class, or focusing heavily on the less represented class of uneven datasets. Thus, to fully reap the benefits of asymmetry in learning, there needs to be a better understanding about effects of the asymmetric loss function in the learning process.
\begin{figure}
 \centering
\includegraphics[width=3.4in]{img/asymSVMimages/quantilegraph}\\
 \caption{Quantile regression for different values of $\theta$.}
 \label{Fig:Quantile Regression}
\end{figure}



\section{Generalized Loss Function}\label{generalform}
The pinball loss described in the previous section can also be applied to a Support Vector Machine for classification. The reader is encouraged to review the following paper \citep{Vapnik98} to get a general background of SVM. The hinge loss innate in SVM is replaced with a pinball loss function used in quantile regression. To further generalize the function an $\epsilon$-sensitive tube commonly used in support vector regression (SVR) is included to allow for a small magnitudes of errors to go unpenalized. The $\epsilon$-sensitive tube makes the classifier less sensitive to observations close to the margin by not penalizing errors within the $\epsilon$-sensitive tube. This can be useful for datasets that are noisy at the margin and allow for lesser penalization to occur for one of the classes. An asymmetric linear penalization property can be attained by allowing for different magnitudes for either sides of the $\epsilon$-sensitive tube. Equation \ref{Eq:GenerallossEqn} shows how different error magnitudes are handled.
\begin{equation}\label{Eq:GenerallossEqn}
l_{\theta}=\begin{cases} 
	-\rho_1(y-f(\mathbf{x})) & \text{if $(y-f(\mathbf{x}))< \epsilon_1$,} \\
 0  &\text{if $\epsilon_1<=(y-f(\mathbf{x}))< 0$.} \\
 0  &\text{if $0<=(y-f(\mathbf{x}))< \epsilon_2$.} \\
 \rho_2(y-f(\mathbf{x})) &\text{if $(y-f(\mathbf{x}))>\epsilon_2$.}
\end{cases}
\end{equation}

The loss function is split into four distinct parts, each with different penalization magnitudes. Figure \ref{Fig:General Loss} shows the resulting loss function. The figure depicts the different parts of the loss function that can be adjusted. One can change the magnitude of an SVM loss by specifying the linear function of the pinball loss or the size of either side of the $\epsilon$-sensitive tube. Both sides of the loss can be customized independently from each other.
\begin{figure}
 \centering
\includegraphics[width=3.4in]{img/asymSVMimages/Generalloss}\\
 \caption{The figure shows the penalty resulted from the error $y-f(x)$. The parameters changes either the length or slope of the lines they are closest to. $\epsilon_1$ and $\epsilon_2$ changes the length of the lines and $\rho_1$ and $\rho_2$ changes the magnitude of the slopes.}
 \label{Fig:General Loss}
\end{figure}



Using the parameters $\epsilon_1, \epsilon_2, \rho_1, \rho_2 \in\mathbb{R}_{\geq0}$ each of the sections have parameters that specify the magnitude in which to apply in the training process of the SVM. Varying the magnitude of $\epsilon_1$ and $\epsilon_2$ elongates or shortens the flat margins on either side of the loss. Increasing the magnitude of $\rho_1$ and $\rho_2$ increases the slopes for the non-zero gradient lines. The modifications provides the ability to customize loss functions for asymmetric problems. In a regular SVM for binary classification, predictions are made based on the following equation.
\begin{equation} \label{Eq:PredictionEqn}
f(x)=sign(\mathbf{w}'\mathbf{x}+b)
\end{equation}
the sign(*) function returns the sign in the embedded expression where a positive sign would indicate a positive class and a negative sign would indicate a negative class. Getting values of $\mathbf{w}$ and $b$ requires the solving of a quadratic program (QP) problem. 

\subsection{Loss Optimization}
To use the proposed loss function in an SVM, the following QP problem is solved.
\begin{equation} \label{Eq:QuantileSVMa}
\begin{array}{cc}
\displaystyle\min_w& \frac{||\mathbf{w}||^2}{2}+C\displaystyle\sum_{i=1}^N(\rho_1\xi_i + \rho_2\xi_i^*) \\
\text{subject to    } & y_i - \mathbf{w}'\mathbf{x}_i - b \leq \xi_i + \epsilon_1 \\
 & \mathbf{w}'\mathbf{x}_i + b -y_i \leq \xi_i^* + \epsilon_2 \\
&i=1,2,...,N\\
&\xi_i,\xi_i^* \geq 0
\end{array}
\end{equation}

The QP problem is typically solved in the dual formulation where the problem is less complex. To get the dual problem, the lagrangian primal $L_p$ as below is converted to its dual formulation.

\[
\begin{array}{cc}
L_p=&\frac{||w||^2}{2}+C\displaystyle\sum_{i=1}^N(\rho_1\xi_i + \rho_2\xi_i^*) \\
& - \displaystyle\sum_{i=1}^N \alpha_i(\xi_i + \epsilon_1 - y_i + \mathbf{w}'\mathbf{x}_i + b)\\
& - \displaystyle\sum_{i=1}^N \alpha_i^*(\xi_i^* + \epsilon_2 + y_i - \mathbf{w}'\mathbf{x}_i - b)\\
&-\displaystyle\sum_{i=1}^N (\eta_i \xi_i + \eta_i^* \xi_i^*)\\
\frac{\partial L_D}{\partial b} = &\displaystyle\sum_{i=1}^N \alpha_i^*  - \displaystyle\sum_{i=1}^N \alpha_i \Rightarrow \displaystyle\sum_{i=1}^N (\alpha_i^* - \alpha_i) = 0 \\
\frac{\partial L_D}{\partial \mathbf{w}} = & \mathbf{w}-\displaystyle\sum_{i=1}^N \alpha_i \mathbf{x}_i+\displaystyle\sum_{i=1}^N \alpha_i^* \mathbf{x}_i \Rightarrow \mathbf{w} = \displaystyle\sum_{i=1}^N \mathbf{x}_i (\alpha_i - \alpha_i^*)\\
\frac{\partial L_D}{\partial \xi_i} = & C\rho_1 - \eta_i -\alpha_i = 0 \Rightarrow  C\rho_1 = \eta_i + \alpha_i \\
\frac{\partial L_D}{\partial \xi_i^*} = &C\rho_2 - \eta_i^* -\alpha_i^* = 0 \Rightarrow  C\rho_2 = \eta_i^* + \alpha_i^*
\end{array}
\]
Substituting the partial derivatives into $L_p$ the lagrangian dual formulation of the problem is obtained
\begin{equation} \label{Eq:QuantileSVMduala}
\begin{array}{cc}
\displaystyle\max_{\alpha_i, \alpha_i^*}& \displaystyle\sum_{i=1}^N y_i(\alpha_i - \alpha_i^*) - \frac{1}{2} \displaystyle\sum_{i=1}^N\displaystyle\sum_{j=1}^N (\alpha_i - \alpha_i^*)(\alpha_j - \alpha_j^*)\mathbf{x}_i' \mathbf{x}_j \\
&-\displaystyle\sum_{i=1}^N (\epsilon_3\alpha_i + \epsilon_4\alpha_i^*) \\
\text{subject to    } & \displaystyle\sum_{i=1}^N(\alpha_i^* - \alpha_i)=0 \\
& \alpha_i \in [0,\rho_1C] \\
& \alpha_i^* \in [0,\rho_2C] \\
\end{array}
\end{equation}
Finally, to determine a class, the following expression is applied and whether the expression yields a positive or negative value determines what the class is.
\begin{equation}\label{finalpredictioneqn1}
f(x)=sign(\displaystyle\sum_{i=1}^N (\alpha_i - \alpha_i^*)\mathbf{x}_i'\mathbf{x} +b)
\end{equation}

The formulation retains the nice properties of SVM that allow for kernels to be used. As the objective function in (\ref{Eq:QuantileSVMduala}) depends on the predictions only though the inner projects of the $\mathbf{x}$'s, the kernel mapping of the original data can be substituted in place of the inner product. The resulting output can then be calculated via the below function. 

\begin{equation}\label{finalpredictioneqn2}
f(x)=sign(\displaystyle\sum_{i=1}^N (\alpha_i - \alpha_i^*)K(\mathbf{x}_i,\mathbf{x})+b)
\end{equation}

\subsection{Parameter Selection for Asymmetric Parameters}
The asymmetric parameters have to be chosen to get the desired result. Observing the second term of the objective function of equation \ref{Eq:QuantileSVMa}, we find the following relationship between $C$, $\rho_1$, and $\rho_2$. It is trivial to show that $C$ can be thought of as the magnitude of penalization and the $\rho$'s being the proportion of $C$ that is assign to each side of the loss. Thus we can assume the general constraint for $\rho_1$ and $\rho_2$.

\begin{equation}\label{rho constraint}
\rho_1 + \rho_2 =1; \rho_1,\rho_2 \geq 0
\end{equation}

The constaints are not necessary tight constraints. If the $\rho$'s are set at close to 0 or 1, the asymmetric SVM may not be able to differentiate between a positive and negative class as it will either predict all observation as negative or positive. A range of operability for $\rho_1$ can be discovered via the training dataset as $\rho_1^{(max)}$ and $\rho_1^{(min)}$. To do so , we set $\rho_1$ close to 0 to train the SVM. We should observe that the predicted values are undifferentiated (i.e. all predicted values are the same). We increase $\rho_1$ by an appropriate step size, retrain, and analyze the output again to check if there is diffentiation. $\rho_1^{(min)}$ is the value when there is differentiation between the predicted values. A similar diagnostic can be conducted to find $\rho_1^{(max)}$. Discovering the range of operability of $\rho_1$ also gives us the range of operability of $\rho_2$ by equation \ref{rho constraint}.

The $\epsilon$'s are less dependent on each other. The higher an $\epsilon$ is, the less penalization will occur on that respective side. However, to accommdate asymmetry, $\epsilon_1 \neq \epsilon_2$. We can implement an accounting for this by using the following constraint.

\begin{equation}\label{epsilon constraint}
\epsilon_1 + \epsilon_2=k \\
\text{, } k \geq 0
\end{equation}

\section{Experiments}
\subsection{Asymmetric Loss SVM on Simulated Data}\label{simulation}
Simulated data was fabricated to test the effectiveness of the asymmetric loss SVM. Positive and negative classes were sampled from two distinct bi-variate normal distributions, creating a distribution of positive and negative classes on a plane that is non-linearly separable. As a control for the asymmetric SVM, a regular construct of SVM by \citet{Vapnik98} and a median SVM where $\rho_1=\rho_2=0.5$ and $\epsilon_1=\epsilon_2=0$ were used as a control and benchmark respectively. The parameters, $\sigma$, for the gaussian kernel and the penalizing parameter C were held constant throughout the experiments at a value of 1 so as to show the marginal improvements that are achieved by adjusting the parameters of the loss function. Here, $\rho_1$ was adjusted to 0.4 and then 0.6 to make the model more averse and prone to classifying a positive class. It then follows from Eq.\ref{rho constraint} that $\rho_2$ is 0.6 and 0.4 respectively. To show how the $\epsilon$-sensitive tube parameters ($\epsilon_1$ and $\epsilon_2$) can obtain better accuracy than that of the median SVM, each of the $\epsilon$'s was set to 1 and the other was set to 0. The trained SVMs utilize the Gaussian kernel function. The heat map in figure \ref{fig:edge} show the classification space of the SVMs. The light regions represent positive while the darker regions represent negative. Observations that are found in the darker regions are classified as negative whereas observations in the lighter area are classified positive. The pluses (+) and the zeros (o) represents the training data of the positive and negative classes, respectively. From the results shown in table \ref{simulatedsvmtable}, the median SVM differs very little from the standard SVM. By comparing the accuracy of either the positive and negative class, one is able to decipher which method yields better accuracy in its prediction. The accuracy for positive and negative classification was better in the median SVM than in the regular SVM. By adjusting $\rho_1$ to 0.4, the accuracy of those data points classified as positive increases. In the other direction, when $\rho_1$ was adjusted to 0.6, the SVM becomes more accurate at identifying the negative class, with the accuracy increasing from 0.601 to 0.746. Comparing Figure \ref{Fig:quantilesvm40} with Figure \ref{Fig:quantilesvm60}, a distinct change in area boundaries for classification can be observed. When $\rho_1=0.4$, there is a larger area in the space of the x's where a point can be classified as a negative class. Changing $\rho_2$ to 0.6 decreases this area resulting in lesser area being classified as the negative class as well as improving the accuracy of classification.
\\Changing the values of $\epsilon_1$ and $\epsilon_2$ yield similar results. When $\epsilon_1=1$, the accuracy for the positive class increases. The heat map of Figure \ref{Fig:quantilesvmP3} illustrates that the classification of positive classes are concentrated in the high density of positive class area in the $x$ space. The converse is true when $\epsilon_1=0$ and $\epsilon_2=1$. From Figure \ref{Fig:quantilesvmP4} we see that classification of the negative class is only concentrated in areas of high concentration of negative class observations and the rest of the area in the figure is classified positive. The resulting accuracy for the negative class increases from that of the baseline median SVM. What is common with the heat maps of the asymmetric SVM is that the class where accuracy is optimized also had a lower number of observations classified to that class. The fewer classified observation in the more risk adverse class is a trade off that one has to make in order to improve accuracy.


\begin{table}[htp]\label{simulatedsvmtable}

\begin{tabular}{r|cccccc}

\hline
           &   {\bf TP} &   {\bf FP} &   {\bf TN} &   {\bf FN} & {\bf Positive Accuracy} & {\bf Negative Accuracy} \\
\hline
\hline
{\bf Standard SVM} &        127 &         90 &        110 &         73 &      0.585 &      0.601 \\

{\bf $\rho_1=0.5$} &        140 &         76 &        124 &         60 &      0.648 &      0.674 \\

{\bf $\rho_1=0.4$} &         37 &         19 &        181 &        163 &      0.661 &      0.526 \\

{\bf $\rho_1=0.6$} &        185 &        156 &         44 &         15 &      0.543 &      0.746 \\

{\bf $\epsilon_1=1$} &         17 &          8 &        192 &        183 &      0.680 &      0.512 \\

{\bf $\epsilon_2=1$} &        191 &        185 &         15 &          9 &      0.508 &      0.625 \\
\hline
\hline
\end{tabular}
\caption{The table shows the confusion matrix of a simulated bi-variate normal data as well as the accuracy for each of the classes. Accuracy is calculated as the percentage of correctly predicted observations. The leftmost column only shows the change in the default values of the generalized asymmetric loss. The default values are $\rho_1=0.5$ and $\epsilon_1=\epsilon2=0$.}
\end{table}

\begin{figure}[htp]
  \begin{center}
    \subfigure[Standard SVM]{\label{Fig:standardsvm}\includegraphics[scale=0.35]{img/asymSVMimages/RegularSVM}}
    \subfigure[Quantile SVM $\rho_1$=0.5]{\label{Fig:quantilesvm50}\includegraphics[scale=0.35]{img/asymSVMimages/MedianSVM}} \\
    \subfigure[Quantile SVM $\rho_1$=0.4]{\label{Fig:quantilesvm40}\includegraphics[scale=0.35]{img/asymSVMimages/p1_40_svm}}
    \subfigure[Quantile SVM $\rho_1$=0.6]{\label{Fig:quantilesvm60}\includegraphics[scale=0.35]{img/asymSVMimages/p1_60_svm}} \\
    \subfigure[Quantile SVM $\epsilon_1$=1]{\label{Fig:quantilesvmP3}\includegraphics[scale=0.35]{img/asymSVMimages/p3_1_svm}}
    \subfigure[Quantile SVM $\epsilon_2$=1]{\label{Fig:quantilesvmP4}\includegraphics[scale=0.35]{img/asymSVMimages/p4_1_svm}}
  \end{center}
  \caption{Heat map of the classification space for various values of $\epsilon$ and $\rho$. The lighter regions are classified as positive and the darker regions are classified as negative}
  \label{fig:edge}
\end{figure}



\subsection{Quantile SVM on Heart Disease Data}
To show how asymmetric SVM can be applied to the healthcare industry, the statlog heart dataset obtained from the UCI website was used. The data consists of 270 observations of patients who may or may not have heart disease. There are 13 different attributes that range from age and sex, to maximum heart rate and fasting blood sugar. Understanding the probability of having heart disease can be beneficial to health care providers and patients. Thus, by using an SVM that will results in high accuracy in either class, the asymmetric SVM is used to predict a subset of patients who have the highest probability of having heart disease or the highest probability of not having heart disease. A regular SVM and a median SVM ($\rho_1=0.5$) were used to establish a benchmark and a baseline for how asymmetric learning can add value. The baseline for the experiments is defined as the starting or "default" setting for the proposed loss function to establish the performance of the loss function before any adjustments were made to the parameters. The benchmark, which is a regular SVM, is what the experiments will be compared against. A 5 fold cross-validation is applied to the data and the results are averaged from the 5 folds. The accuracy of the positive class compared to the baseline median SVM improved from 0.754 to 0.95 when $\rho_1$ is changed to 0.2 and the accuracy of the negative class improved from 0.819 to 0.961 when $\rho_1$ was changed to 0.8. The results also improved when both sides of the $\epsilon$-sensitive tube were modified. When $\epsilon_1=1$, the accuracy was 1 and when $\epsilon_2=1$, the accuracy for the negative class was 0.983. It must be noted that although the accuracy got better, the improvements also resulted in lesser observations being classified for the class being optimized.

Next, the loss function is tested by adjusting both $\rho$ and the $\epsilon$-sensitive tube of the loss function to achieve better accuracy. The simultaneous adjustment of two parameters offers greater flexibility to how errors are penalized. However, one cannot adjust the $\rho$'s without accounting for the $\epsilon$'s and vice versa as both sets of parameters affect the risk aversion of the trained SVM. To accounting for both sets of parameters, the magnitude for the parameters had to be lower than the previous SVMs as now there were 2 parts of the loss function that were being used to achieve high precision. Setting $\rho_1=0.3$ and $\epsilon_1=0.5$ increased the positive class accuracy to 0.891. To optimize the precision of the negative class, $\rho_1$ was set to 0.7 and $\epsilon_2$ to 0.5, increasing the precision from the baseline to 0.898. 

Instead of adjusting both the $\rho$ and $\epsilon$ parameters in a single SVM, the use of two separate SVMs, one with the $\epsilon$'s adjusted and the other with the $\rho$'s adjusted, can be constructed to evaluate if adjusting both sets of parameters within an SVM is superior to combining the results of two separate SVMs. In this two separate SVM experiment, the consensus of the SVMs will indicate the classification of the class of interest. Combining the results of the SVM where $\rho_1=0.2$ and the SVM where $\epsilon_1=1$, an observation is only classified positive if both SVMs agree. A similar consensus strategy is done with the SVM where $\rho_1=0.8$ and the SVM where $\epsilon_2=1$. The results of this consensus framework yield better accuracy than that of adjusting both sets of parameters within one SVM. 

The previous SVM constructions were optimize to accurately predict one of the classes. It is also possible to construct an algorithm with the use of these SVMs to achieve accuracy for both classes. Up to this point, there was no accounting to ensure that an observation that is classified positive by an SVM optimized for the positive class was not going to be classified as negative if the parameter values were reversed. In other words, if an observation was classified positive when $\rho=0.2$, there was no check to ensure that observation was not classified as negative when $\rho=.8$. Accounting for this ensures robustness in the asymmetric accuracy and could make an asymmetric prediction better. Thus, an extension to focusing on just one class, an array of SVMs can be trained to form a combined model that optimizes the precision of both classes simultaneously. This is done by taking the combined vote of multiple asymmetric SVMs. For this paper, a simple voting system is used where four SVMs, each with an adjustment of only one of the loss function's parameter. However, because the individual SVMs are optimized to only classify one of the classes, they can only vote on the class they are optimizing. For instance, if an SVM trained to predict positive class classifies an observation as negative, that classification will be discounted. The SVMs that are optimized for the positive class ($\rho_1=.3$ and $\epsilon_1=.5$) each scores an observation 1 for a positive classification and 0 for a negative classification. Conversely, the SVMs that are optimized for the negative class($\rho_1=.7$ and $\epsilon_2=.5$) each scores a -1 for a negative classification and 0 for a positive classification. The results for all four SVMs are summed and if the summed score is 2, the combined classifier classifies the observation as positive and if the summed score is -2 it is classified as negative. Those observations that have neither a -2 or a 2 summed score will not be classified as the combined classifier is unable to determine accurately the class of the observation. The precision for the combined voting method was 0.879 for the positive class and 0.9 for the negative class. Thus the method shows improvement in both classes from the baseline of the median SVM.

\begin{table}[htp]
% Table generated by Excel2LaTeX from sheet 'Sheet3'
\begin{tabular}{rc|cccc}
\hline
           &            & Accuracy  & Accuracy Std &          N &      N Std \\
\hline
\hline
Regular SVM & Postive Class &      0.764 &      0.073 &     18.400 &      2.966 \\

           & Negative Class &      0.819 &      0.115 &     24.000 &      4.183 \\
\hline
    $\rho_1=0.5$ & Postive Class &      0.794 &      0.076 &     18.200 &      2.168 \\

           & Negative Class &      0.821 &      0.120 &     25.000 &      3.536 \\
\hline
    $\rho_1=0.2$ & Postive Class &      0.950 &      0.112 &      3.600 &      1.949 \\

           & Negative Class &      0.595 &      0.086 &     29.800 &      3.564 \\
\hline
    $\rho_1=0.8$ & Postive Class &      0.554 &      0.077 &     23.200 &      2.588 \\

           & Negative Class &      0.942 &      0.093 &     11.200 &      0.837 \\
\hline
      $\epsilon_1=1$ & Postive Class &      1.000 &      0.000 &      5.200 &      1.643 \\

           & Negative Class &      0.615 &      0.077 &     30.000 &      3.536 \\
\hline
      $\epsilon_2=1$ & Postive Class &      0.535 &      0.076 &     23.600 &      3.286 \\

           & Negative Class &      0.961 &      0.054 &      9.400 &      2.074 \\
\hline
$\rho_1=0.3$ and $\epsilon_1=0.5$ & Postive Class &      0.891 &      0.104 &      7.800 &      1.304 \\

           & Negative Class &      0.642 &      0.084 &     29.000 &      3.536 \\
\hline
$\rho_1=0.7$ and $\epsilon_2=0.5$ & Postive Class &      0.590 &      0.060 &     22.400 &      2.302 \\

           & Negative Class &      0.898 &      0.130 &     14.400 &      2.967 \\
\hline
 Consensus & Postive Class &      1.000 &      0.000 &      2.800 &      2.387 \\

           & Negative Class &      0.983 &      0.037 &      7.400 &      2.881 \\
\hline
  Combined & Postive Class &      0.879 &      0.111 &      8.800 &      1.483 \\

           & Negative Class &      0.900 &      0.125 &     16.600 &      2.702 \\
\hline
\hline
\end{tabular}
\caption{Precision and count (N) of the number classified in each class. The values in the Accuracy and N columns are the average of the 5 fold cross-validation. The Accuracy Std and N Std are the standard deviations of the 5 fold cross-validation. The leftmost column show the parameters that were changed from the baseline asymmetric loss function. The consensus row show the results of using the consensus of two SVMs, each with either the $\epsilon$ or $\rho$ adjusted. The Combined row shows the results of using a voting system from a multiple SVM ensemble. Thus, for the Combined row, the positive and negative classes were estimated simultaneously}
\end{table}

\subsection{Quantile SVM on Blood Transfusion Data}
To show how having an asymmetric loss function can be useful in classifying data with uneven classes, a dataset retrieved from the Blood Transfusion Service Center in Hsin-Chu City in Taiwan was used \citep{Yeh09}. The set has 5 predictor variables that were used to classify whether or not a person will donate blood. The dataset, consisting of 748 observations, has only 23\% of rows that are in the positive class (donated blood). This presents the problem of an unbalanced class dataset, a problem that is common in medical data. Typically for such problems, using a standard SVM would often result in all the data being classified as negative. It is thus beneficial to apply an asymmetric SVM to penalize classifying a FP less so as to increase the number of observations being classified as positive. This change to the loss function while increasing the observations of positive classification, also may reduce the accuracy of the observations classified positive. The predictor variables are first standardized to mean 0 and standard deviation 1 on the full dataset to prevent the dominance of variables with high magnitude. Like the heart disease data, the parameter of the kernel and penalizing parameter \emph{C} were held constant at 1. To try and recreate the testing scenario of \citet{Yeh09} paper where 500 observations were randomly picked to be insample and the remainder to be outsample, a 3 folds cross-validation was used as the number of folds for approximating the number of in and out sample for each run. A 3 fold cross-validation results in each fold having approximately 499 insample observations, which is close to the number of insample observations used in \citet{Yeh09}. Thus a 3 fold cross-validation was conducted and the results are presented in Table \ref{bloodtransfusion}.


\begin{table}[htp]
\begin{tabular}{rc|cccc}
\hline
           &            & Accuracy  & Accuracy Std &          TP &      TP Std \\
\hline
\hline
Regular SVM & Postive Class &      0.379 &      0.048 &      4.000 &      1.732 \\

           & Negative Class &      0.769 &      0.043 &    183.000 &      5.292 \\
\hline
    $\rho_1=0.5$ & Postive Class &      0.806 &      0.174 &      2.333 &      0.577 \\

           & Negative Class &      0.769 &      0.038 &    189.333 &      9.292 \\
\hline
    $\rho_1=0.7$ & Postive Class &      0.411 &      0.092 &      4.333 &      2.082 \\

           & Negative Class &      0.769 &      0.042 &    182.667 &      5.508 \\
\hline
    $\epsilon_2=0.5$ & Postive Class &      0.379 &      0.048 &      4.000 &      1.732 \\

           & Negative Class &      0.769 &      0.043 &    183.000 &      5.292 \\
\hline
$\rho_1=0.6$ or $\epsilon_2=0.4$ & Postive Class &      0.409 &      0.079 &      4.000 &      1.732 \\

           & Negative Class &      0.769 &      0.431 &    183.667 &      5.686 \\
\hline
  Combined & Postive Class &      0.392 &      0.021 &      8.667 &      2.082 \\

           & Negative Class &      0.778 &      0.048 &    176.667 &      7.234 \\
\hline
\hline
\end{tabular}
\caption{Results of blood transfusion data from a 3 fold cross-validation. The Precision and TP are averaged from the 3 folds. Precision Std and TP Std are the standard deviations of the 3 folds}
\label{bloodtransfusion}
\end{table}


As the objective is to increase the number of positive class while maintaining reasonable accuracy, the loss function should be formed to penalize a FP less. Setting $\rho_1=0.7$, the positive class precision was 0.411 and N increased marginally from the regular SVM but doubled when compared with the baseline of the median SVM. Setting $\epsilon_2$ to 0.5 resulted in no increase in the number of TP from the regular SVM. Instead of just adjusting a single parameter, both the $\epsilon$ and $\rho$ parameters in the loss function can be adjusted simultaneously to increase the positive observations classified. $\rho_1$ was set to 0.6 and $\epsilon_2$ to 0.4. To maintain a reasonable level of precision, the magnitudes of the parameters were set lower than the previous SVMs that had only one parameter changed. By manipulating both parameters, better precision in the positive class was achieved without compromising the number of TP. The use of multiple asymmetric SVMs is implemented to achieve better positive class hits. Because $\epsilon$ and $\rho$ parameters handle errors in a slightly different way, the ability to estimate results separately and seek consensus could yield better results. Thus, two separate SVMs, one with $\rho_1=.7$ and the other with $\epsilon_2=0.5$, were trained. An observation is classified as positive if it was classified as positive in either of the SVMs. The resulting precision is 0.392 and the number of TP increased to 8.667.

\section{Conclusion}
 This paper explores the use of a generalized asymmetric loss function to achieve asymmetric loss and applies this loss function to SVM for classification problems. As a further extension of the pinball loss function that is found in quantile regression, the generalized loss function is flexible enough to not only set different penalization standards for FP and FN, it is able to allow for the adjustment of an  $\epsilon$-sensitive tube. This generalized loss function serves two different purposes: training classifiers when there is imbalanced data, and optimizing accuracy for a class of interest. This technique is useful in a variety of applications and the paper has shown that it is particularly beneficial in health care. In applying the method to heart disease where there are obvious advantages to doctors and insurance companies in finding a subset of patients with high or low risk of getting a heart disease, it was shown that the use of the loss function proposed in this paper improved the accuracy of the positive and negative class from that of the regular SVM. The trade off for the increase in accuracy came at the cost of a reduced number of observations being classified as the class that is being optimized. Using a consensus approach allowed for the combination of multiple asymmetric SVM classifiers to be used for class prediction. An SVM classifier designed to minimize FP and be combined with one that is designed to minimize FN to produce a classifier that optimizes both cases. The use of blood transfusion data on the proposed loss function illustrate the benefits of using asymmetry to increase the number of observations classified as positive for an imbalanced dataset. The use of two asymmetric loss function SVM, each with either $\rho$ or $\epsilon$ adjusted, was shown to improve both the accuracy and the number of TPs from just using a regular SVM. As the experiments presented served as examples to show how a change in the loss function could potentially improve the performance of accuracy and increase the number of classified observations, they do not present the optimized abilities of such loss functions. Much improvements can be achieved if a search is done to find a combination of the hyper-parameters of the kernel, $\epsilon$, $\rho$, and the penalizing parameter \emph{C}, through cross validation. More importantly, using an asymmetric loss function requires the decision of the trade-off between the number of instances classified and accuracy. Such decisions are idiosyncratic to individual problems and the agents would have to decide what values of classified instances and accuracy they are comfortable with. Nevertheless, the general problem
 \begin{equation}
 \max \alpha(\text{accuracy}) + \beta(\text{number of classified instances})
 \end{equation}
could be further formalized and optimized by discovering the relationship between precision and classified instances and letting the user decide values of $\alpha$ and $\beta$. Finally, even though the paper has demonstrated the marginal benefit gained in the medical field by using asymmetric loss, the use of such methodology can serve a useful purpose in other disciplines and applications.



